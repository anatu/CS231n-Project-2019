{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE REFERENCES\n",
    "# https://towardsdatascience.com/how-to-build-an-image-classifier-for-waste-sorting-6d11d3c9c478\n",
    "# https://github.com/danny95333/Trash-Classification-based-on-CNN\n",
    "from linear_classifier import *\n",
    "from linear_svm import *\n",
    "from softmax import *\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imghdr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the relative path to the PROCESSED trashnet data\n",
    "# i.e. this path should go to \"train\", \"test\", \"val\" folders each of which \n",
    "# contain images for the train, test, and validation sets respectively.\n",
    "dataRoot = \"../../datasets/trashnet/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# DATA AUGMENTATION\n",
    "# Loading the dataset into memory and applying transforms\n",
    "# NOTE: May have to not use this for the baseline\n",
    "##########################\n",
    "\n",
    "# import torch\n",
    "# from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "# # Data augmentation and normalization for training\n",
    "# # Just normalization for validation\n",
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "\n",
    "\n",
    "# # Create an ImageFolder dataloader for the input data\n",
    "# # See https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(outDataPath, x),\n",
    "#                                           data_transforms[x]) for x in [\"train\", \"val\"]}\n",
    "\n",
    "# # Create DataLoader objects for each of the image datasets returned by ImageFolder\n",
    "# # See https://pytorch.org/docs/stable/data.html\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "#                                               shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "# datasets_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "# class_names = image_datasets['train'].classes\n",
    "\n",
    "# print(datasets_sizes)\n",
    "# print(class_names)\n",
    "# print(image_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement data loading manually as np arrays\n",
    "##########################\n",
    "# Loading the dataset into memory and applying transforms\n",
    "##########################\n",
    "\n",
    "# TODO: Preinitialize X etc. as zeros\n",
    "\n",
    "def load_image( infilename ) :\n",
    "    '''\n",
    "    Helper function to manually load in images. Accepts image path infilename \n",
    "    and returns the numpy array representation of the image data\n",
    "    (Need final X to be of dims (N, H, W, D))\n",
    "    '''\n",
    "    img = Image.open( infilename )\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    return data\n",
    "\n",
    "# Load the training data\n",
    "arrayList = []\n",
    "labelList = []\n",
    "trainRoot = os.path.join(dataRoot, \"train\")\n",
    "for c in os.listdir(os.path.join(trainRoot)):\n",
    "    for item in os.listdir(os.path.join(trainRoot, c)):\n",
    "        if imghdr.what(os.path.join(trainRoot, c, item)):\n",
    "            # Convert the image to a numpy array\n",
    "            data = load_image(os.path.join(trainRoot, c, item))\n",
    "            # Add to the array which we will stack at the end to form X\n",
    "            arrayList.append(data)\n",
    "            # Add label to array for Y\n",
    "            labelList.append(c)\n",
    "X_train = np.stack(tuple(arrayList))\n",
    "y_train = np.array(labelList)\n",
    "        \n",
    "            \n",
    "# Load the validation data\n",
    "arrayList = []\n",
    "labelList = []\n",
    "valRoot = os.path.join(dataRoot, \"val\")\n",
    "for c in os.listdir(os.path.join(valRoot)):\n",
    "    for item in os.listdir(os.path.join(valRoot, c)):\n",
    "        if imghdr.what(os.path.join(valRoot, c, item)):\n",
    "            # Convert the image to a numpy array\n",
    "            data = load_image(os.path.join(valRoot, c, item))\n",
    "            # Add to the array which we will stack at the end to form X\n",
    "            arrayList.append(data)\n",
    "            # Add label to array for Y\n",
    "            labelList.append(c)\n",
    "X_val = np.stack(tuple(arrayList))\n",
    "y_val = np.array(labelList)\n",
    "\n",
    "# Load the test data\n",
    "arrayList = []\n",
    "labelList = []\n",
    "testRoot = os.path.join(dataRoot, \"test\")\n",
    "for item in os.listdir(testRoot):\n",
    "    if imghdr.what(os.path.join(testRoot, item)):\n",
    "        # Produce label from filename\n",
    "        ########\n",
    "        # TODO: Go back to dataloader and change it so we bucket test data into the same \n",
    "        # subfolder structure as train and val data\n",
    "        ########\n",
    "        c = os.path.splitext(re.sub(\"[0-9]+\", \"\", item))[0]\n",
    "        data = load_image(os.path.join(testRoot, item))\n",
    "        arrayList.append(data)\n",
    "        labelList.append(c)\n",
    "X_test = np.stack(tuple(arrayList))\n",
    "y_test = np.array(labelList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten X matrices down for SVM classification\n",
    "imageDim = 384*512*3\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], imageDim))\n",
    "X_val = X_val.reshape((X_val.shape[0], imageDim))\n",
    "X_test = X_test.reshape((X_test.shape[0], imageDim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549, 589824)\n",
      "(1549,)\n",
      "(950, 589824)\n",
      "(950,)\n",
      "(970, 589824)\n",
      "(970,)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check dimensions\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the class labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "classes = [\"cardboard\", \"compost\", \"glass\", \"metal\", \"paper\", \"plastic\", \"trash\"]\n",
    "le = LabelEncoder()\n",
    "le.fit(classes)\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 1549 rows of training data\n",
      "iteration 0 / 1500: loss 51980.603545\n",
      "iteration 100 / 1500: loss 20442.439398\n",
      "iteration 200 / 1500: loss 7677.857989\n",
      "iteration 300 / 1500: loss 3449.274737\n",
      "iteration 400 / 1500: loss 2430.900509\n",
      "iteration 500 / 1500: loss 2050.436010\n",
      "iteration 600 / 1500: loss 1153.225606\n",
      "iteration 700 / 1500: loss 1325.494756\n",
      "iteration 800 / 1500: loss 1605.925831\n",
      "iteration 900 / 1500: loss 1251.200552\n",
      "iteration 1000 / 1500: loss 1318.792032\n",
      "iteration 1100 / 1500: loss 973.098466\n",
      "iteration 1200 / 1500: loss 896.706693\n",
      "iteration 1300 / 1500: loss 692.072233\n",
      "iteration 1400 / 1500: loss 1300.415057\n",
      "Training Complete. That took 3829.853825s\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "svm = LinearSVM()\n",
    "tic = time.time()\n",
    "print(\"Training model with {} rows of training data\".format(X_train.shape[0]))\n",
    "loss_hist = svm.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4,\n",
    "                      num_iters=1500, verbose=True)\n",
    "toc = time.time()\n",
    "print('Training Complete. That took %fs' % (toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear SVM on raw pixels final test set accuracy: 0.241237\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best svm on test set\n",
    "y_test_pred = svm.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('linear SVM on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
